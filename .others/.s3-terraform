
resource "aws_s3_bucket_public_access_block" "secure_bucket_block" {
  bucket = aws_s3_bucket.secure_bucket.id

  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}


=====

Perfect ‚Äî let‚Äôs structure this the best-practice way üî•

You want:
	‚Ä¢	IAM + KMS policies for the ‚Äúinfrastructure access‚Äù part ‚Üí in one Terraform file
	‚Ä¢	S3 bucket with KMS encryption ‚Üí in a separate Terraform file

I‚Äôll give you both clearly separated, clean, and ready to use.

‚∏ª

üß© Folder Structure (recommended)

terraform/
‚îú‚îÄ‚îÄ iam_infra.tf        # IAM user, roles, policies, KMS key
‚îî‚îÄ‚îÄ s3_encryption.tf    # S3 bucket with SSE-KMS encryption


‚∏ª

üß± File 1: iam_infra.tf

Creates:
	‚Ä¢	KMS key for S3 encryption
	‚Ä¢	IAM user
	‚Ä¢	IAM role (with permissions for S3 + KMS)
	‚Ä¢	IAM policy for the user to assume the role

#################################################
# IAM & KMS INFRASTRUCTURE CONFIGURATION
#################################################

data "aws_caller_identity" "current" {}

# --- Create KMS Key ---
resource "aws_kms_key" "s3_kms_key" {
  description             = "KMS key for encrypting S3 objects"
  deletion_window_in_days = 10
  enable_key_rotation     = true

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Sid    = "Allow account access"
        Effect = "Allow"
        Principal = {
          AWS = "arn:aws:iam::${data.aws_caller_identity.current.account_id}:root"
        }
        Action   = "kms:*"
        Resource = "*"
      }
    ]
  })
}

# --- IAM User ---
resource "aws_iam_user" "infra_user" {
  name = "infra-user"
}

# --- IAM Role (S3 + KMS Access) ---
resource "aws_iam_role" "infra_role" {
  name = "infra-s3-kms-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Principal = {
          AWS = "arn:aws:iam::${data.aws_caller_identity.current.account_id}:user/${aws_iam_user.infra_user.name}"
        }
        Action = "sts:AssumeRole"
      }
    ]
  })
}

# --- IAM Policy for S3 + KMS Access ---
resource "aws_iam_policy" "infra_s3_kms_policy" {
  name        = "infra-s3-kms-policy"
  description = "Allow access to S3 and KMS decryption for infra role"

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Sid    = "AllowS3Access"
        Effect = "Allow"
        Action = [
          "s3:ListBucket",
          "s3:GetObject",
          "s3:PutObject"
        ]
        Resource = [
          "arn:aws:s3:::*",
          "arn:aws:s3:::*/*"
        ]
      },
      {
        Sid    = "AllowKMSDecrypt"
        Effect = "Allow"
        Action = [
          "kms:Decrypt",
          "kms:Encrypt",
          "kms:GenerateDataKey*"
        ]
        Resource = aws_kms_key.s3_kms_key.arn
      }
    ]
  })
}

# --- Attach policy to role ---
resource "aws_iam_role_policy_attachment" "infra_role_attach" {
  role       = aws_iam_role.infra_role.name
  policy_arn = aws_iam_policy.infra_s3_kms_policy.arn
}

# --- IAM Policy for User to Assume the Role ---
resource "aws_iam_policy" "allow_assume_infra_role" {
  name        = "allow-assume-infra-role"
  description = "Allow user to assume infra role"

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Action = "sts:AssumeRole"
        Resource = aws_iam_role.infra_role.arn
      }
    ]
  })
}

# --- Attach AssumeRole Policy to User ---
resource "aws_iam_user_policy_attachment" "user_assume_infra_role_attach" {
  user       = aws_iam_user.infra_user.name
  policy_arn = aws_iam_policy.allow_assume_infra_role.arn
}


‚∏ª

ü™£ File 2: s3_encryption.tf

Creates:
	‚Ä¢	S3 bucket
	‚Ä¢	Enables server-side encryption (SSE-KMS)
	‚Ä¢	Enforces that all uploads use KMS encryption

#################################################
# S3 BUCKET WITH SSE-KMS ENCRYPTION
#################################################

resource "aws_s3_bucket" "infra_bucket" {
  bucket = "infra-secure-bucket-example"
}

# --- S3 Bucket Encryption ---
resource "aws_s3_bucket_server_side_encryption_configuration" "infra_encryption" {
  bucket = aws_s3_bucket.infra_bucket.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm     = "aws:kms"
      kms_master_key_id = aws_kms_key.s3_kms_key.arn
    }
  }
}

# --- Enforce Encryption on All PUT Requests ---
resource "aws_s3_bucket_policy" "enforce_sse_kms" {
  bucket = aws_s3_bucket.infra_bucket.id

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Sid       = "DenyUnEncryptedObjectUploads"
        Effect    = "Deny"
        Principal = "*"
        Action    = "s3:PutObject"
        Resource  = "${aws_s3_bucket.infra_bucket.arn}/*"
        Condition = {
          StringNotEquals = {
            "s3:x-amz-server-side-encryption" = "aws:kms"
          }
        }
      }
    ]
  })
}


‚∏ª

‚úÖ How to Deploy

cd terraform
terraform init
terraform apply


‚∏ª

üß© Summary of What You Get

File	Purpose
iam_infra.tf	Creates IAM user, role, policies, and KMS key
s3_encryption.tf	Creates S3 bucket and applies SSE-KMS encryption + policy enforcement


‚∏ª

Would you like me to extend this setup to include multiple IAM users that can assume the same infra role (for a shared DevOps or automation team)?


=======

Perfect üëç ‚Äî here‚Äôs the complete all-in-one PowerShell script that builds a secure, reusable Terraform module repo with:
‚úÖ secure S3 bucket (ACL, encryption, versioning, public-block, logging)
‚úÖ reusable environment tfvars & backend configs
‚úÖ GitHub Actions workflow with fmt, tflint, tfsec, plan/apply logic
‚úÖ everything neatly scaffolded for your team

‚∏ª

üß© setup-terraform-secure.ps1

# ==========================================
# Script: setup-terraform-secure.ps1
# Purpose: Create secure Terraform S3 module structure + GitHub Actions workflow
# ==========================================

$basePath = "terraform-infra"
$modulePath = "$basePath/modules/s3-backend"
$envPath = "$basePath/environments"
$workflowPath = "$basePath/.github/workflows"

# --- Create directories ---
New-Item -ItemType Directory -Force -Path $modulePath, $envPath, $workflowPath | Out-Null

# --- Root main.tf ---
@"
terraform {
  required_version = ">= 1.6.0"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

module "s3_backend" {
  source             = "./modules/s3-backend"
  s3_bucket_name     = var.s3_bucket_name
  logging_bucket_name = var.logging_bucket_name
  tags               = var.tags
}
"@ | Set-Content "$basePath/main.tf"

# --- Root variables.tf ---
@"
variable "aws_region" {
  description = "AWS region"
}

variable "s3_bucket_name" {
  description = "Name of the S3 bucket to create"
}

variable "logging_bucket_name" {
  description = "Optional logging bucket name"
  default     = null
}

variable "tags" {
  description = "Common tags for all resources"
  type        = map(string)
}
"@ | Set-Content "$basePath/variables.tf"

# --- Root backend.tf ---
@"
terraform {
  backend "s3" {}
}
"@ | Set-Content "$basePath/backend.tf"

# --- Secure S3 Module (main.tf) ---
@"
resource "aws_s3_bucket" "tf_state" {
  bucket = var.s3_bucket_name

  tags = merge(var.tags, {
    ManagedBy = "Terraform"
  })
}

resource "aws_s3_bucket_acl" "tf_state_acl" {
  bucket = aws_s3_bucket.tf_state.id
  acl    = "private"
}

resource "aws_s3_bucket_public_access_block" "tf_state_block" {
  bucket                  = aws_s3_bucket.tf_state.id
  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}

resource "aws_s3_bucket_versioning" "tf_state_versioning" {
  bucket = aws_s3_bucket.tf_state.id
  versioning_configuration {
    status = "Enabled"
  }
}

resource "aws_s3_bucket_server_side_encryption_configuration" "tf_state_encryption" {
  bucket = aws_s3_bucket.tf_state.id
  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

resource "aws_s3_bucket_logging" "tf_state_logging" {
  count         = var.logging_bucket_name != null ? 1 : 0
  bucket        = aws_s3_bucket.tf_state.id
  target_bucket = var.logging_bucket_name
  target_prefix = "logs/\${var.s3_bucket_name}/"
  depends_on    = [aws_s3_bucket_public_access_block.tf_state_block]
}

output "bucket_name" {
  value = aws_s3_bucket.tf_state.bucket
}
"@ | Set-Content "$modulePath/main.tf"

# --- Secure S3 Module variables.tf ---
@"
variable "s3_bucket_name" {
  description = "The name of the S3 bucket to create"
  type        = string
}

variable "logging_bucket_name" {
  description = "Optional S3 bucket name for access logs"
  type        = string
  default     = null
}

variable "tags" {
  description = "Tags to apply to resources"
  type        = map(string)
  default     = {}
}
"@ | Set-Content "$modulePath/variables.tf"

# --- Environment tfvars ---
@"
aws_region         = "eu-central-1"
s3_bucket_name     = "mycompany-tfstate-dev"
logging_bucket_name = "mycompany-tf-logs"
tags = {
  Environment = "dev"
  Owner       = "DevOpsTeam"
}
"@ | Set-Content "$envPath/dev.tfvars"

@"
aws_region         = "eu-central-1"
s3_bucket_name     = "mycompany-tfstate-qa"
logging_bucket_name = "mycompany-tf-logs"
tags = {
  Environment = "qa"
  Owner       = "DevOpsTeam"
}
"@ | Set-Content "$envPath/qa.tfvars"

@"
aws_region         = "eu-central-1"
s3_bucket_name     = "mycompany-tfstate-prod"
logging_bucket_name = "mycompany-tf-logs"
tags = {
  Environment = "prod"
  Owner       = "DevOpsTeam"
}
"@ | Set-Content "$envPath/prod.tfvars"

# --- Backend configs ---
@"
bucket         = "team-shared-terraform-state"
key            = "dev/terraform.tfstate"
region         = "eu-central-1"
dynamodb_table = "terraform-locks"
encrypt        = true
"@ | Set-Content "$envPath/dev.backend.conf"

@"
bucket         = "team-shared-terraform-state"
key            = "qa/terraform.tfstate"
region         = "eu-central-1"
dynamodb_table = "terraform-locks"
encrypt        = true
"@ | Set-Content "$envPath/qa.backend.conf"

@"
bucket         = "team-shared-terraform-state"
key            = "prod/terraform.tfstate"
region         = "eu-central-1"
dynamodb_table = "terraform-locks"
encrypt        = true
"@ | Set-Content "$envPath/prod.backend.conf"

# --- GitHub Workflow (terraform-deploy.yml) ---
$workflowContent = @"
name: Terraform Secure Deploy

on:
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy (dev/qa/prod)'
        required: true
        default: 'dev'

permissions:
  id-token: write
  contents: read

jobs:
  terraform:
    runs-on: ubuntu-latest
    env:
      AWS_REGION: eu-central-1
      ENV: \${{ github.event.inputs.environment || 'dev' }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::<ACCOUNT_ID>:role/GitHubActionsDeployRole
          aws-region: \${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.9.8

      - name: Terraform Format Check
        working-directory: terraform-infra
        run: terraform fmt -check -recursive

      - name: Run TFLint
        uses: terraform-linters/setup-tflint@v4
        with:
          tflint_version: latest
      - run: |
          cd terraform-infra
          tflint --init
          tflint

      - name: Run tfsec Security Scan
        uses: aquasecurity/tfsec-action@v1.0.0
        with:
          working_directory: terraform-infra

      - name: Terraform Init
        working-directory: terraform-infra
        run: terraform init -backend-config=environments/\${{ env.ENV }}.backend.conf -reconfigure

      - name: Terraform Plan
        working-directory: terraform-infra
        run: terraform plan -var-file=environments/\${{ env.ENV }}.tfvars -out=tfplan

      - name: Terraform Apply (Auto for dev/qa)
        if: \${{ env.ENV != 'prod' }}
        working-directory: terraform-infra
        run: terraform apply -auto-approve tfplan

      - name: Terraform Apply (Manual Approval for prod)
        if: \${{ env.ENV == 'prod' }}
        uses: chriskilding/approval-action@v2
        with:
          approvers: user1,user2
          min-approvals: 1

      - name: Terraform Apply (After approval)
        if: \${{ env.ENV == 'prod' }}
        working-directory: terraform-infra
        run: terraform apply -auto-approve tfplan
"@

Set-Content "$workflowPath/terraform-deploy.yml" $workflowContent

Write-Host "`n‚úÖ Secure Terraform + GitHub workflow structure created successfully!"
Write-Host "Path: $basePath"


‚∏ª

üß† What This Script Does

Step	Purpose
üóÇÔ∏è Creates full Terraform folder tree	modules, environments, .github/workflows
üõ°Ô∏è Adds secure S3 bucket Terraform module	with ACL, encryption, versioning, block public access, logging
üîß Adds environment tfvars & backend configs	dev, qa, prod
üß∞ Adds GitHub workflow	with fmt, tflint, tfsec, plan, apply
üöÄ Supports reusable modules	You can later add EC2, RDS, ALB modules easily


‚∏ª

‚öôÔ∏è How to Run
	1.	Save as setup-terraform-secure.ps1
	2.	Run from PowerShell:

./setup-terraform-secure.ps1


	3.	Commit & push:

git add .
git commit -m "Secure Terraform setup with GitHub Actions"
git push origin main



‚∏ª

Would you like me to extend this so it auto-detects your AWS account ID from your local AWS CLI profile and replaces <ACCOUNT_ID> in the GitHub workflow automatically?