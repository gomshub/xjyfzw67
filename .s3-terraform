Let’s build a clean, reusable Terraform setup that creates an S3 backend for Terraform state, supports environment-specific .tfvars, and is initialized via a GitHub commit/push (CI/CD).

We’ll cover:
	1.	Repository structure (GitHub-ready)
	2.	Terraform code for S3 backend + DynamoDB lock table
	3.	Environment tfvars pattern
	4.	Backend configuration pattern
	5.	GitHub Actions pipeline to auto-apply on commit

⸻

🧩 1. Repository Structure

terraform-s3-backend/
├── main.tf
├── backend.tf
├── variables.tf
├── outputs.tf
├── environments/
│   ├── dev.tfvars
│   ├── qa.tfvars
│   └── prod.tfvars
├── .github/
│   └── workflows/
│       └── terraform.yml


⸻

⚙️ 2. Terraform Code

main.tf

provider "aws" {
  region = var.aws_region
}

# S3 bucket for Terraform state
resource "aws_s3_bucket" "tf_state" {
  bucket = var.s3_bucket_name
  acl    = "private"

  versioning {
    enabled = true
  }

  server_side_encryption_configuration {
    rule {
      apply_server_side_encryption_by_default {
        sse_algorithm = "AES256"
      }
    }
  }

  tags = {
    Environment = var.environment
    ManagedBy   = "Terraform"
  }
}

# DynamoDB table for state locking
resource "aws_dynamodb_table" "tf_lock" {
  name         = "${var.s3_bucket_name}-lock"
  billing_mode = "PAY_PER_REQUEST"
  hash_key     = "LockID"

  attribute {
    name = "LockID"
    type = "S"
  }

  tags = {
    Environment = var.environment
    ManagedBy   = "Terraform"
  }
}

output "s3_bucket_name" {
  value = aws_s3_bucket.tf_state.bucket
}

output "dynamodb_table_name" {
  value = aws_dynamodb_table.tf_lock.name
}


⸻

variables.tf

variable "aws_region" {
  description = "AWS region where S3 bucket and DynamoDB will be created"
  type        = string
}

variable "environment" {
  description = "Environment name (dev, qa, prod)"
  type        = string
}

variable "s3_bucket_name" {
  description = "Name of the S3 bucket for Terraform state"
  type        = string
}


⸻

outputs.tf

output "terraform_backend" {
  value = {
    bucket         = aws_s3_bucket.tf_state.bucket
    dynamodb_table = aws_dynamodb_table.tf_lock.name
    region         = var.aws_region
  }
}


⸻

backend.tf (template for future modules)

After this initial setup, your future Terraform projects can use this backend:

terraform {
  backend "s3" {
    bucket         = "your-tfstate-bucket-name"
    key            = "project-name/env/terraform.tfstate"
    region         = "your-region"
    dynamodb_table = "your-tfstate-bucket-name-lock"
    encrypt        = true
  }
}

You’ll replace values dynamically during terraform init using:

terraform init \
  -backend-config="bucket=$(terraform output -raw s3_bucket_name)" \
  -backend-config="key=myproject/dev/terraform.tfstate" \
  -backend-config="region=$(terraform output -raw aws_region)" \
  -backend-config="dynamodb_table=$(terraform output -raw dynamodb_table_name)" \
  -reconfigure


⸻

🧮 3. Environment-Specific .tfvars

environments/dev.tfvars

aws_region      = "us-east-1"
environment     = "dev"
s3_bucket_name  = "mycompany-tfstate-dev"

environments/qa.tfvars

aws_region      = "us-east-1"
environment     = "qa"
s3_bucket_name  = "mycompany-tfstate-qa"

environments/prod.tfvars

aws_region      = "us-east-1"
environment     = "prod"
s3_bucket_name  = "mycompany-tfstate-prod"


⸻

🚀 4. GitHub Actions CI/CD Workflow

.github/workflows/terraform.yml

name: Terraform S3 Backend Setup

on:
  push:
    branches:
      - main
    paths:
      - '**/*.tf'
      - 'environments/*.tfvars'

jobs:
  terraform:
    name: Apply Terraform
    runs-on: ubuntu-latest

    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_DEFAULT_REGION: us-east-1

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.9.8

      - name: Initialize Terraform
        run: terraform init

      - name: Validate Terraform
        run: terraform validate

      - name: Plan Terraform (Dev)
        run: terraform plan -var-file=environments/dev.tfvars -out=tfplan

      - name: Apply Terraform (Dev)
        run: terraform apply -auto-approve tfplan

✅ This ensures:
	•	S3 and DynamoDB backend are created via GitHub commit.
	•	Environment-specific vars come from separate .tfvars files.
	•	State can be backed up to AWS S3 automatically.

⸻

🧠 Summary

Component	Purpose
main.tf	Creates S3 + DynamoDB backend
backend.tf	Template for other modules’ backend configs
environments/*.tfvars	Environment-specific configs
terraform.yml	Automates init → plan → apply on GitHub commit
S3 + DynamoDB	Stores & locks Terraform state securely


⸻

Would you like me to extend this with a remote backend promotion pipeline (e.g., dev → qa → prod using GitHub Environments) to fully automate environment promotion?