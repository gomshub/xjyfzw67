
Thanks! Here’s the enhanced version that:
	•	Lists multiple Parquet files from a given S3 prefix.
	•	Converts each to original file type or CSV.
	•	Adds each converted file to a single in-memory ZIP.
	•	Returns the ZIP to the client.

⸻

1. api.py – Multi-file zip from S3 prefix

# api.py

import boto3
import os
import pandas as pd
import io
import zipfile

s3 = boto3.client('s3')

def list_parquet_files(bucket_name, prefix):
    response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)
    return [obj['Key'] for obj in response.get('Contents', []) if obj['Key'].endswith('.parquet')]


def convert_df_to_bytes(df, ext):
    if ext == 'csv':
        return df.to_csv(index=False).encode('utf-8')
    elif ext == 'xls':
        buf = io.BytesIO()
        df.to_excel(buf, index=False)
        buf.seek(0)
        return buf.read()
    elif ext == 'xml':
        return df.to_xml(index=False).encode('utf-8')
    elif ext in ['txt', 'out']:
        return df.to_csv(index=False, sep='\t').encode('utf-8')
    else:
        raise ValueError(f"Unsupported extension: {ext}")


def zip_converted_files(bucket_name, prefix, as_original=True):
    zip_buffer = io.BytesIO()
    files = list_parquet_files(bucket_name, prefix)

    if not files:
        raise Exception(f"No .parquet files found under {prefix}")

    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for key in files:
            # Get metadata and read parquet
            metadata = s3.head_object(Bucket=bucket_name, Key=key)['Metadata']
            original_ext = metadata.get('original_extension', 'csv').lower()

            base_filename = os.path.basename(key).replace('.parquet', '')
            filename = f"{base_filename}.{original_ext if as_original else 'csv'}"

            parquet_stream = io.BytesIO()
            s3.download_fileobj(bucket_name, key, parquet_stream)
            parquet_stream.seek(0)

            df = pd.read_parquet(parquet_stream)

            if as_original:
                content = convert_df_to_bytes(df, original_ext)
            else:
                content = df.to_csv(index=False).encode('utf-8')

            zipf.writestr(filename, content)

    zip_buffer.seek(0)
    return zip_buffer, f"{prefix.strip('/').replace('/', '_')}_converted.zip"



⸻

2. app.py – Accepts S3 prefix and returns zipped result

# app.py

from flask import Flask, request, Response, jsonify
from api import zip_converted_files

app = Flask(__name__)

@app.route('/download-zip', methods=['GET'])
def download_zip():
    bucket = request.args.get('bucket')
    prefix = request.args.get('prefix')
    as_original = request.args.get('as_original', 'true').lower() == 'true'

    if not bucket or not prefix:
        return jsonify({"error": "Missing 'bucket' or 'prefix' parameter"}), 400

    try:
        zip_buffer, zip_name = zip_converted_files(bucket, prefix, as_original)
        return Response(
            zip_buffer.getvalue(),
            mimetype='application/zip',
            headers={
                "Content-Disposition": f"attachment; filename={zip_name}"
            }
        )
    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)



⸻

Test it like this:

curl "http://localhost:5000/download-zip?bucket=my-bucket&prefix=abc/29-APR-2025/&as_original=true" --output batch.zip

Each .parquet file will be downloaded, converted, and zipped into batch.zip.

Would you like to make this a POST endpoint with JSON body (e.g., to filter or select specific files)?

==#=
Here’s the complete solution to return the converted file as a ZIP archive, split into two clean files:

⸻

1. api.py – Converts and zips the file in-memory

# api.py

import boto3
import os
import pandas as pd
import io
import zipfile

s3 = boto3.client('s3')

def download_and_zip_file(bucket_name, s3_key, as_original=True):
    # Fetch metadata
    metadata = s3.head_object(Bucket=bucket_name, Key=s3_key)['Metadata']
    original_ext = metadata.get('original_extension')

    if not original_ext:
        raise ValueError("Missing 'original_extension' in metadata")

    base_filename = os.path.basename(s3_key).replace('.parquet', '')
    parquet_stream = io.BytesIO()
    s3.download_fileobj(bucket_name, s3_key, parquet_stream)
    parquet_stream.seek(0)

    # Read parquet into DataFrame
    df = pd.read_parquet(parquet_stream)

    # Convert based on flag
    if as_original:
        ext = original_ext.lower()
        output_filename = f"{base_filename}.{ext}"
        content = convert_df_to_bytes(df, ext)
    else:
        output_filename = f"{base_filename}.csv"
        content = df.to_csv(index=False).encode('utf-8')

    # Write content to zip in memory
    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
        zf.writestr(output_filename, content)

    zip_buffer.seek(0)
    return zip_buffer, f"{base_filename}.zip"


def convert_df_to_bytes(df, ext):
    if ext == 'csv':
        return df.to_csv(index=False).encode('utf-8')
    elif ext == 'xls':
        buf = io.BytesIO()
        df.to_excel(buf, index=False)
        buf.seek(0)
        return buf.read()
    elif ext == 'xml':
        return df.to_xml(index=False).encode('utf-8')
    elif ext in ['txt', 'out']:
        return df.to_csv(index=False, sep='\t').encode('utf-8')
    else:
        raise ValueError(f"Unsupported original extension: {ext}")



⸻

2. app.py – Flask API that returns ZIP response

# app.py

from flask import Flask, request, Response, jsonify
from api import download_and_zip_file

app = Flask(__name__)

@app.route('/download', methods=['GET'])
def download_file():
    bucket = request.args.get('bucket')
    key = request.args.get('key')
    as_original = request.args.get('as_original', 'true').lower() == 'true'

    if not bucket or not key:
        return jsonify({"error": "Missing 'bucket' or 'key' parameter"}), 400

    try:
        zip_buffer, zip_filename = download_and_zip_file(bucket, key, as_original)
        return Response(
            zip_buffer.getvalue(),
            mimetype='application/zip',
            headers={
                "Content-Disposition": f"attachment; filename={zip_filename}"
            }
        )
    except Exception as e:
        return jsonify({"error": str(e)}), 500


if __name__ == '__main__':
    app.run(debug=True)



⸻

Example Request:

curl "http://localhost:5000/download?bucket=my-bucket&key=abc/29-APR-2025/file1_xml.parquet&as_original=true" --output result.zip

Let me know if you want to support batch downloads or multiple files in one ZIP.

=#=#=#
Absolutely! Here’s how you can split the code cleanly into app.py and api.py, with no use of send_file(), and using Response to stream the file from memory.

⸻

api.py – Core logic to fetch, convert, and return file content and metadata

# api.py

import boto3
import os
import pandas as pd

s3 = boto3.client('s3')

def download_and_convert_file(bucket_name, s3_key, local_dir='/tmp', as_original=True):
    metadata = s3.head_object(Bucket=bucket_name, Key=s3_key)['Metadata']
    original_ext = metadata.get('original_extension')

    if not original_ext:
        raise ValueError("Missing 'original_extension' in metadata")

    base_filename = os.path.basename(s3_key).replace('.parquet', '')
    parquet_path = os.path.join(local_dir, f"{base_filename}.parquet")

    s3.download_file(bucket_name, s3_key, parquet_path)
    df = pd.read_parquet(parquet_path)

    # Determine output format and convert
    if as_original:
        ext = original_ext.lower()
        filename = f"{base_filename}.{ext}"
        output_path = os.path.join(local_dir, filename)

        if ext == 'csv':
            df.to_csv(output_path, index=False)
            mimetype = 'text/csv'
        elif ext == 'xls':
            df.to_excel(output_path, index=False)
            mimetype = 'application/vnd.ms-excel'
        elif ext == 'xml':
            df.to_xml(output_path, index=False)
            mimetype = 'application/xml'
        elif ext in ['txt', 'out']:
            df.to_csv(output_path, sep='\t', index=False)
            mimetype = 'text/plain'
        else:
            raise ValueError(f"Unsupported extension: {ext}")
    else:
        filename = f"{base_filename}.csv"
        output_path = os.path.join(local_dir, filename)
        df.to_csv(output_path, index=False)
        mimetype = 'text/csv'

    # Read file content into memory
    with open(output_path, 'rb') as f:
        file_bytes = f.read()

    return file_bytes, filename, mimetype



⸻

app.py – Flask app that calls the function and returns the response

# app.py

from flask import Flask, request, Response, jsonify
from api import download_and_convert_file

app = Flask(__name__)

@app.route('/download', methods=['GET'])
def download_file():
    bucket = request.args.get('bucket')
    key = request.args.get('key')
    as_original = request.args.get('as_original', 'true').lower() == 'true'

    if not bucket or not key:
        return jsonify({"error": "Missing 'bucket' or 'key' parameter"}), 400

    try:
        file_bytes, filename, mimetype = download_and_convert_file(bucket, key, as_original=as_original)

        return Response(
            file_bytes,
            mimetype=mimetype,
            headers={
                "Content-Disposition": f"attachment; filename={filename}"
            }
        )

    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)



⸻

To Run:

python app.py

Example API Call:

curl "http://localhost:5000/download?bucket=my-bucket&key=abc/29-APR-2025/file1_xml.parquet&as_original=true" --output file.xml



⸻

Let me know if you want to make this a POST API instead of GET with query params.